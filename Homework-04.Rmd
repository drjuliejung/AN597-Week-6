---
title: "Homework-04"
author: "Julie Jung"
date: "October 17, 2017"
output: html_document
---

[1] Write a simple R function, Z.prop.test(), that can perform one- or two-sample Z-tests for proportion data, using the following guidelines.

The function should contain a check for the rules of thumb we have talked about (n∗p>5n∗p>5 and n∗(1−p)>5n∗(1−p)>5) to ensure the validity of assuming the normal distribution in both the one- and two-sample settings. If this is violated, the function should still complete but it should also print an appropriate warning message.

The function should return a list containing the members Z (the test statistic), P (the appropriate p value), and CI (the two-sided CI with respect to “conf.level” around p1 in the case of a one-sample test and around p2-p1 in the case of a two-sample test). For all test alternatives (“two.sided”, “greater”, “less”), calculate symmetric CIs based on quantiles of the normal distribution rather than worrying about calculating single-limit confidence bounds.

```{r}

# p1, no default == estimated sample proportion (i.e., based on your sample data)
# n1, no default == estimated sample size (i.e., based on your sample data)

# p2, default is NULL == second sample proportion data (in the event of a two-sample test)
# n2, default is NULL == second sample size data (in the event of a two-sample test)

# p0, no default == the expected value for the population proportion

# alternative (default “two.sided”), to be used in the same way as in the function t.test(). 
# conf.level (default 0.95), to be used in the same way as in the function t.test(). 

Z.prop.test <- function(p1, n1, p2=NULL, n2=NULL, p0, alternative=c("two.sided", "less", "greater"), conf.level=0.95) {
  
  OK <- complete.cases(p1, n1, p0)
    p1 <- p1[OK]
    n1 <- n1[OK]
    p0 <- p0[OK]
  
  if (n1*p1 < 5)
    warning("failed one or more validity tests; i.e. assumption is not met")
  if (n1 * (1-p1) < 5)
    warning("failed one or more validity tests; i.e. assumption is not met")
  
  if (is.null(c(p2,n2))) {
        z <- (p1-p0)/sqrt((p0 * (1-p0)/n1))
  
      lower <- p1 - qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
      upper <- p1 + qnorm(0.975) * sqrt(p1 * (1 - p1)/n1)
      ci <- c(lower, upper)
  
      if (alternative == "less"){
        p[i] <- pnorm(z, lower.tail=TRUE) # calculates the associated p value
      }
  
      if (alternative == "greater"){
        p[i] <- pnorm(z, lower.tail = FALSE)  # calculates the associated p value
      }
  
      if (alternative == "two.tailed") {
            if (z > 0) 
                {
                  p[i] <- 2 * pnorm(z, lower.tail = FALSE)
                }
            if (z < 0) 
                {
                  p[i] <- 2 * pnorm(z, lower.tail = TRUE)
                }
        }
    }
  
    ## if want to perform a 2-sample test 
    # When conducting a two-sample test, it should be p1 that is tested as being smaller or larger than p2 when alternative=“less” or alternative=“greater”, the same as in the use of x and y in the function t.test().
  
  else  {
     pstar= p1+p2
     pci= p2-p1
     ntot= n1 + n2
        z <- (p2 - p1)/sqrt((pstar * (1 - pstar)) * (1/n1) + 1/n2)
	  
    lower <- pci - qnorm(0.975) * sqrt(pci * (1 - pci)/ntot)
    upper <- pci + qnorm(0.975) * sqrt(pci * (1 - pci)/ntot)
    ci <- c(lower, upper)
    
        if (alternative == "less") {
            p <- pnorm(z, lower.tail = TRUE)
        }
        if (alternative == "greater") {
            p <- pnorm(z, lower.tail = FALSE)
        }
        if (alternative == "two.sided") {
            if (z > 0) 
                {
                  p <- 2 * pnorm(z, lower.tail = FALSE)
                } 
            if (z < 0) 
                {
                  p <- 2 * pnorm(z, lower.tail = TRUE)
                }  

        }
    }
  
  # The function should perform a one-sample Z-test using p1, n1, and p0 if either p2 or n2 (or both) is NULL.

   result <- list(statistic = z,
  	 p.value = p,
		 conf.int = ci,
		 alternative = alternative)
  
    return(result)
  }

```


[2] The dataset from Kamilar and Cooper has in it a large number of variables related to life history and body size. 

For this exercise, the end aim is to fit a simple linear regression model to predict 
- longevity (MaxLongevity_m): measured in months 
- from species’ brain size (Brain_Size_Species_Mean): measured in grams. 

```{r}
# Import file from github
library(curl)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall17/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
```

Do the following for both (1) longevity~brain size and (2) log(longevity)~log(brain size).

Fit the regression model and, using {ggplot2}, produce a scatterplot with the fitted line superimposed upon the data. Append the the fitted model equation to your plot

```{r}
# (1) longevity~brain size
library(ggplot2)

mI <- lm(MaxLongevity_m ~ Brain_Size_Species_Mean, data = d)
t <- coef(summary(mI))
t <- data.frame(unlist(t))
colnames(t) <- c("Est", "SE", "t", "p")
t
beta0 <- t$Est[1] #The intercept, β0, is the PREDICTED value of y when the value of x is zero.
beta1 <- t$Est[2] #The slope, β1 is EXPECTED CHANGE in units of y for every 1 unit of change in x

ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) +
  geom_point()+
  geom_smooth(method="lm", se=F, color="black")+
  annotate("text", x = 350, y = 300, label = "y = 1.21799 * x + 248.95227")+
  ylab("Longevity (months)")+
  theme_bw(20) +
  xlab("Brain size (g)")

# (2) log(longevity)~log(brain size).

mI <- lm(log(MaxLongevity_m) ~ log(Brain_Size_Species_Mean), data = d)
t <- coef(summary(mI))
t <- data.frame(unlist(t))
colnames(t) <- c("Est", "SE", "t", "p")
t
beta0 <- t$Est[1] #The intercept, β0, is the PREDICTED value of y when the value of x is zero.
beta1 <- t$Est[2] #The slope, β1 is EXPECTED CHANGE in units of y for every 1 unit of change in x

ggplot(data = d, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m))) +
  geom_point()+
  geom_smooth(method="lm", se=F, color="black")+
  annotate("text", x = 4, y = 5, label = "y = 0.2341496 * x + 4.8789509")+
  ylab("Log of Longevity")+
  theme_bw(20) +
  xlab("Log of Brain size")

```

Identify and interpret the point estimate of the slope (β1), as well as the outcome of the test associated with the hypotheses H0: β1 = 0; HA: β1 ≠ 0. Also, find a 90 percent CI for the slope (β1) parameter.

--> The slope, β1 is the EXPECTED CHANGE in units of y for every 1 unit of change in x. For every gram of increase in brain size, we can expect to see an increase in longevity of β1 months. See above for values from examples. 

```{r}
#confidence intervals for our estimates 

t$lower <- t$Est - qt(0.95, df = 998) * t$SE
t$upper <- t$Est + qt(0.95, df = 998) * t$SE
ci <- c(t$lower, t$upper)  # by hand
ci

ci <- confint(mI, level = 0.90)  # using the results of lm()
ci

```

Using your model, add lines for the 90 percent confidence and prediction interval bands on the plot and add a legend to differentiate between the lines.

```{r}

###### non-log model

v = seq(from = 0, to = 500, by = 1)
m = lm(data=d, MaxLongevity_m~Brain_Size_Species_Mean)
ci = predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "confidence", level = 0.90)
pi = predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "prediction", level = 0.90)
df <- data.frame(cbind(v, ci, pi))
names(df) <- c("Brain_Size_Species_Mean", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(df)
s <- shapiro.test(m$residuals)
s
plot(m)


ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m)) +
  geom_point()+
  geom_line(data = df, aes(x = v, y = CIfit), colour = "black", lwd = 1)+
  geom_line(data = df, aes(x = v, y = CIlwr), colour = "blue")+
  geom_line(data = df, aes(x = v, y = CIupr), colour = "blue")+
  geom_line(data = df, aes(x = v, y = PIlwr), colour = "red")+
  geom_line(data = df, aes(x = v, y = PIupr), colour = "red")+
  annotate("text", x = 200, y = 950, label = "lm fit: y = 1.21799 * x + 248.95227")+
  annotate("text", x = 350, y = 225, label = "red = 90% PI, blue = 90% CI")+
  ylab("Longevity (months)")+
  theme_bw(20) +
  xlab("Brain size (g)")

```

Produce a point estimate and associated 90 percent PI for the longevity of a species whose brain weight is 800 gm. 
```{r}
ppi <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = 800), interval = "prediction", level = 0.90)  # for a single value
ppi
```

```{r}

### LOG model 

v = seq(from = 0, to = 7, by = 1)
m = lm(data=d, log(MaxLongevity_m)~log(Brain_Size_Species_Mean))
ci = predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "confidence", level = 0.90)
pi = predict(m, newdata = data.frame(Brain_Size_Species_Mean = v), interval = "prediction", level = 0.90)
df <- data.frame(cbind(v, ci, pi))
names(df) <- c("Brain_Size_Species_Mean", "CIfit", "CIlwr", "CIupr", "PIfit", "PIlwr", "PIupr")
head(df)
s <- shapiro.test(m$residuals)
s
plot(m)

ggplot(data = d, aes(x = log(Brain_Size_Species_Mean), y = log(MaxLongevity_m))) +
  geom_point()+
  geom_line(data = df, aes(x = v, y = CIfit), colour = "black", lwd = 1)+
  geom_line(data = df, aes(x = v, y = CIlwr), colour = "blue")+
  geom_line(data = df, aes(x = v, y = CIupr), colour = "blue")+
  geom_line(data = df, aes(x = v, y = PIlwr), colour = "red")+
  geom_line(data = df, aes(x = v, y = PIupr), colour = "red")+
  annotate("text", x = 3.5, y = 4.7, label = "red = 90% PI, blue = 90% CI")+
  ylab("log of longevity")+
  theme_bw(20) +
  xlab("log of brain size")
```

Do you trust the model to predict observations accurately for this value of the explanatory variable? Why or why not?
Looking at your two models, which do you think is better? Why?

NOTE: my log model seems flawed - and the 0 point yields an error and the predicted and CI fits don't seem very accurate. This certainly is a factor to consider when deciding which model is the more accurate.. 

HOWEVER, from the plot(m) results from each model, the log model seems like a much better fit! We can tell from the residual plots. The residual plot from the log model just looks like a linear relationship from the 2 variables. The output looks more normal - qqplot is more on the line. fitted values vs. square of standardized residuals looks more like a line. 

Also when we ran our shapiro tests, the log model was non-significantly non-normal (i.e. normally distributed), because the P-value was 0.7404. But the non-log model was significantly non-normal (P=0.0001729). 